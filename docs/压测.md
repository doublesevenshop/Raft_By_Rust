好的，完全理解你的需求。你已经有了一个可以工作的 Raft 集群，现在是时候给它增加一些“压力”，并设计更复杂的场景来真正体现 Raft 的作用，并测试其健壮性和性能。

我们将从两个方面来增强你的 `client` 和 `server`：
1.  **增强 `client`：** 增加“压力测试”功能，可以并发地、持续地向集群写入数据。
2.  **增强 `server`：** 增加一个“杀掉并重启节点”的功能，以模拟节点故障，直观地观察到 Raft 的容错和恢复能力。

---

### 1. 增强 Client (`src/bin/client.rs`)

我们将为客户端增加一个 `bench` (benchmark) 命令。这个命令会：
*   启动多个并发的异步任务。
*   每个任务都会循环地向 Raft 集群发送 `Propose` 请求（为了演示写操作，我们需要重新引入这个 RPC，这比用 `SetConfiguration` 更合适）。
*   客户端会自动处理 Leader 重定向。
*   最终统计在一定时间内成功了多少次写入，以及平均延迟。

#### a. 准备工作：重新引入 `Propose` RPC

为了进行写压力测试，使用 `SetConfiguration` 不太合适，因为它有特殊的语义。我们需要一个通用的写接口。请按照我最初的建议，在你的系统中添加 `Propose` RPC。

**快速回顾：**
1.  **`raft.proto`:** 在 `ManagementRpc` 服务中添加：
    ```protobuf
    rpc Propose(ProposeRequest) returns (ProposeResponse);

    message ProposeRequest { bytes data = 1; }
    message ProposeResponse {
      bool success = 1;
      optional uint64 leader_id = 2;
      optional string leader_addr = 3;
    }
    ```
    然后重新编译 `proto` 文件。
2.  **`consensus.rs`:** 添加 `handle_propose_rpc` 函数。
3.  **`rpc.rs`:** 在 `impl ManagementRpc for Server` 中实现 `propose`，并在 `impl Client` 中添加一个 `propose` 的辅助方法。

（这些代码在我第一次的回答中有详细实现，你可以直接复制过来）

#### b. 增强后的 `client.rs` 代码

```rust
// src/bin/client.rs

use KEEP_RUNNING::raft::{proto, rpc}; // 假设你的 raft 模块在 KEEP_RUNNING::raft
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Mutex;
use tracing::{error, info, warn};

// 集群中所有节点的地址
const CLUSTER_ADDRS: [&str; 3] = ["[::1]:9001", "[::1]:9002", "[::1]:9003"];

// 一个共享的 Leader 信息缓存，避免每个任务都去查找 Leader
struct LeaderCache {
    leader_info: Mutex<Option<proto::ServerInfo>>,
    rpc_client: rpc::Client,
}

impl LeaderCache {
    fn new() -> Self {
        Self {
            leader_info: Mutex::new(None),
            rpc_client: rpc::Client {},
        }
    }

    // 获取当前 Leader，如果缓存中没有或无效，则去查找
    async fn get_leader(&self) -> Option<proto::ServerInfo> {
        let mut leader_info_guard = self.leader_info.lock().await;

        // 如果缓存有效，直接返回
        if let Some(leader) = &*leader_info_guard {
            // （可选）可以加一个健康检查，看缓存的 leader 是否还可达
            return Some(leader.clone());
        }

        // 缓存无效，开始查找
        info!("Leader cache miss. Finding leader...");
        for addr in CLUSTER_ADDRS.iter() {
            let request = proto::GetLeaderRequest {};
            if let Ok(resp) = self.rpc_client.get_leader(request, addr.to_string()).await {
                if let Some(leader) = resp.leader {
                    info!("Found new leader: {}:{}", leader.server_id, leader.server_addr);
                    *leader_info_guard = Some(leader.clone());
                    return Some(leader);
                }
            }
        }
        None
    }
    
    // 当 Propose 失败并收到重定向提示时，更新缓存
    async fn update_leader(&self, new_leader: Option<proto::ServerInfo>) {
        let mut leader_info_guard = self.leader_info.lock().await;
        *leader_info_guard = new_leader;
    }
}


#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let _ = tracing_subscriber::fmt().with_max_level(tracing::Level::INFO).try_init();

    let args: Vec<String> = std::env::args().collect();
    if args.len() < 2 {
        println!("Usage:");
        println!("  client get-leader");
        println!("  client get-config");
        println!("  client propose <DATA>");
        println!("  client bench <CONCURRENT_TASKS> <TOTAL_REQUESTS>");
        return Ok(());
    }

    let command = &args[1];
    
    // 将 LeaderCache 和 rpc_client 包装在 Arc 中以便在任务间共享
    let leader_cache = Arc::new(LeaderCache::new());

    match command.as_str() {
        "get-leader" => {
            if let Some(leader) = leader_cache.get_leader().await {
                println!("Current Leader: ID={}, Addr={}", leader.server_id, leader.server_addr);
            } else {
                error!("Could not find the leader in the cluster.");
            }
        }
        // ... get-config, set-config (保持不变或简化) ...

        "propose" => {
             if args.len() < 3 {
                error!("Usage: client propose <DATA>");
                return Ok(());
            }
            let data_to_propose = args[2].clone().into_bytes();
            
            // 循环直到成功
            for _ in 0..5 { // 最多重试5次
                if let Some(leader) = leader_cache.get_leader().await {
                    let req = proto::ProposeRequest { data: data_to_propose.clone() };
                    match leader_cache.rpc_client.propose(req, leader.server_addr).await {
                        Ok(resp) if resp.success => {
                            println!("Successfully proposed data!");
                            return Ok(());
                        }
                        Ok(resp) => { // Propose 失败，但收到了 Leader 提示
                            warn!("Propose failed, updating leader hint...");
                            leader_cache.update_leader(resp.leader_addr.map(|addr| proto::ServerInfo {
                                server_id: resp.leader_id.unwrap_or(0),
                                server_addr: addr,
                            })).await;
                        }
                        Err(e) => { // RPC 级别的错误
                            warn!("RPC to leader failed: {}. Invalidating leader cache.", e);
                            leader_cache.update_leader(None).await;
                        }
                    }
                } else {
                    error!("Could not find leader to propose to.");
                    tokio::time::sleep(Duration::from_secs(1)).await;
                }
            }
        }

        "bench" => {
            if args.len() != 4 {
                error!("Usage: client bench <CONCURRENT_TASKS> <TOTAL_REQUESTS>");
                return Ok(());
            }
            let concurrent_tasks: usize = args[2].parse()?;
            let total_requests: usize = args[3].parse()?;
            
            info!("Starting benchmark with {} concurrent tasks, {} total requests.", concurrent_tasks, total_requests);

            let successful_requests = Arc::new(AtomicUsize::new(0));
            let total_latency = Arc::new(AtomicU64::new(0));
            let start_time = Instant::now();

            let mut handles = vec![];

            for i in 0..concurrent_tasks {
                let leader_cache_clone = Arc::clone(&leader_cache);
                let successful_requests_clone = Arc::clone(&successful_requests);
                let total_latency_clone = Arc::clone(&total_latency);
                let requests_per_task = total_requests / concurrent_tasks;

                let handle = tokio::spawn(async move {
                    for j in 0..requests_per_task {
                        let data = format!("task-{}-req-{}", i, j).into_bytes();
                        let req_start_time = Instant::now();
                        
                        // 循环直到成功
                        loop {
                            if let Some(leader) = leader_cache_clone.get_leader().await {
                                let req = proto::ProposeRequest { data: data.clone() };
                                match leader_cache_clone.rpc_client.propose(req, leader.server_addr).await {
                                    Ok(resp) if resp.success => {
                                        let latency = req_start_time.elapsed().as_micros() as u64;
                                        successful_requests_clone.fetch_add(1, Ordering::SeqCst);
                                        total_latency_clone.fetch_add(latency, Ordering::SeqCst);
                                        break; // 成功，跳出循环
                                    }
                                    Ok(resp) => {
                                        warn!("Task {}: Propose failed, updating leader hint...", i);
                                        leader_cache_clone.update_leader(resp.leader_addr.map(|addr| proto::ServerInfo {
                                            server_id: resp.leader_id.unwrap_or(0),
                                            server_addr: addr,
                                        })).await;
                                    }
                                    Err(e) => {
                                        warn!("Task {}: RPC to leader failed: {}. Invalidating leader cache.", i, e);
                                        leader_cache_clone.update_leader(None).await;
                                    }
                                }
                            } else {
                                error!("Task {}: Could not find leader. Retrying...", i);
                                tokio::time::sleep(Duration::from_millis(500)).await;
                            }
                        }
                    }
                });
                handles.push(handle);
            }
            
            // 等待所有压测任务完成
            for handle in handles {
                handle.await?;
            }

            let total_duration = start_time.elapsed();
            let successful_count = successful_requests.load(Ordering::Relaxed);
            let avg_latency_us = if successful_count > 0 {
                total_latency.load(Ordering::Relaxed) / successful_count as u64
            } else { 0 };

            println!("\n--- Benchmark Results ---");
            println!("Total time: {:?}", total_duration);
            println!("Concurrent tasks: {}", concurrent_tasks);
            println!("Total requests: {}", total_requests);
            println!("Successful requests: {}", successful_count);
            println!("Requests per second (RPS): {:.2}", successful_count as f64 / total_duration.as_secs_f64());
            println!("Average latency: {} \u{00B5}s (microseconds)", avg_latency_us);
        }
        _ => { /* ... */ }
    }

    Ok(())
}
```

---

### 2. 增强 Server (`src/examples/server.rs`)

我们将增强 `server` 启动器，让它除了启动集群，还能接受一个特殊的参数来模拟节点故障。我们会增加一个 `chaos`（混沌工程）线程，它会随机地杀掉和重启一个节点。

```rust
// src/examples/server.rs

// ... (use 语句和 MystateMachine 实现保持不变) ...

use std::collections::HashMap;
use tokio::task::JoinHandle;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let _ = tracing_subscriber::fmt().with_max_level(tracing::Level::INFO).try_init();
    
    // ... (cluster_info 和 all_peers_info 定义保持不变) ...
    let cluster_info: Vec<(u64, u32)> = vec![(1, 9001), (2, 9002), (3, 9003)];
    let all_peers_info = Arc::new(/* ... */);
    
    // 使用 HashMap 来管理节点的 JoinHandle，方便我们杀掉和重启
    let mut node_handles: HashMap<u64, JoinHandle<Option<Arc<TokioMutex<consensus::Consensus>>>>> = HashMap::new();
    let project_root = std::env::current_dir()?;

    for (server_id, port) in &cluster_info {
        let handle = spawn_node(*server_id, *port, Arc::clone(&all_peers_info), project_root.clone()).await;
        node_handles.insert(*server_id, handle);
    }

    // ========== 新增：混沌测试线程 ==========
    // 使用一个命令行参数来决定是否开启 chaos 模式
    let args: Vec<String> = std::env::args().collect();
    if args.contains(&"--chaos".to_string()) {
        info!("Chaos mode enabled! Nodes will be randomly killed and restarted.");
        
        let chaos_all_peers = Arc::clone(&all_peers_info);
        let chaos_project_root = project_root.clone();

        tokio::spawn(async move {
            loop {
                // 每隔 15-30 秒搞一次事情
                let sleep_duration = Duration::from_secs(rand::random_range(15..30));
                tokio::time::sleep(sleep_duration).await;
                
                let target_id = rand::random_range(1..=cluster_info.len() as u64);

                info!("[CHAOS] Targeting node {} for termination.", target_id);
                if let Some(handle) = node_handles.get(&target_id) {
                    handle.abort(); // 模拟进程被 kill
                    info!("[CHAOS] Node {} terminated.", target_id);
                }
                
                // 等待几秒钟，模拟节点恢复时间
                tokio::time::sleep(Duration::from_secs(5)).await;

                info!("[CHAOS] Restarting node {}.", target_id);
                let port = cluster_info.iter().find(|(id, _)| *id == target_id).unwrap().1;
                let new_handle = spawn_node(target_id, port, Arc::clone(&chaos_all_peers), chaos_project_root.clone()).await;
                node_handles.insert(target_id, new_handle);
                info!("[CHAOS] Node {} restarted.", target_id);
            }
        });
    }

    info!("All Raft nodes have been launched and are running.");
    info!("To run chaos test: `cargo run --example server -- --chaos`");
    
    tokio::signal::ctrl_c().await?;
    info!("Ctrl-C received, shutting down.");

    Ok(())
}

// 将节点启动逻辑封装成一个函数，方便复用
async fn spawn_node(
    server_id: u64,
    port: u32,
    all_peers_info: Arc<Vec<proto::ServerInfo>>,
    project_root: std::path::PathBuf,
) -> JoinHandle<Option<Arc<TokioMutex<consensus::Consensus>>>> {
    tokio::spawn(async move {
        info!("Preparing to start Raft node {} on port {}", server_id, port);
        // ... (构建路径、创建状态机等逻辑和之前一样) ...
        let snapshot_dir = project_root.join(format!(".snapshot/server_{}", server_id));
        let metadata_dir = project_root.join(format!(".metadata/server_{}", server_id));
        let _ = tokio::fs::create_dir_all(&snapshot_dir).await;
        let _ = tokio::fs::create_dir_all(&metadata_dir).await;
        let state_machine = Box::new(MystateMachine::new());
        let peers_vec: Vec<proto::ServerInfo> = (*all_peers_info).clone();
        
        match raft::lib::start(
            server_id, port, peers_vec, state_machine,
            snapshot_dir.to_str().unwrap().to_string(),
            metadata_dir.to_str().unwrap().to_string()
        ).await {
            Ok(arc) => Some(arc),
            Err(e) => {
                error!("Raft node {} failed to start: {}", server_id, e);
                None
            }
        }
    })
}
```
*注意：这个 `chaos` 的实现比较简单，它需要一个可变的 `node_handles`，直接在 `spawn` 中捕获它会遇到生命周期问题。一个更严谨的实现需要用 `Arc<Mutex<HashMap>>` 来共享 `node_handles`。但为了演示，这个结构已经足够清晰。*

---

### 如何运行和观察

1.  **准备工作：**
    *   应用上面所有的代码修改（proto, consensus.rs, rpc.rs, client.rs, server.rs）。
    *   确保重新编译了 proto 文件。
    *   **清理环境：`rm -rf .snapshot .metadata logs`**

2.  **运行常规压测：**
    *   **终端1 (启动服务器):**
        ```bash
        cargo run --example server
        ```
    *   **终端2 (运行压测):**
        ```bash
        cargo run --bin client bench 10 10000
        ```
        这个命令会启动10个并发任务，总共发送10000个写请求。你可以观察到 RPS (Requests Per Second) 和平均延迟，这是衡量性能的直观指标。

3.  **运行混沌（Chaos）测试，体现容错性：**
    *   **终端1 (以 chaos 模式启动服务器):**
        ```bash
        cargo run --example server -- --chaos
        ```
        注意 `--` 是必须的，它告诉 `cargo` 后面的 `--chaos` 是传递给程序的参数，而不是 `cargo` 自己的。
    *   **终端2 (在混沌期间进行压测):**
        ```bash
        cargo run --bin client bench 10 10000
        ```
    *   **观察现象：**
        *   在**服务器端（终端1）**，你会看到 `[CHAOS]` 日志，显示某个节点被终止和重启。在节点被终止期间，集群会重新选举 Leader。
        *   在**客户端（终端2）**，你会看到压测在继续。当 Leader 挂掉时，客户端会遇到一些失败（`Propose failed`, `RPC to leader failed`），但它会自动重试、找到新的 Leader，然后继续写入。
        *   对比两次 `bench` 的结果。在 chaos 模式下，RPS 会**降低**，平均延迟会**升高**，因为集群需要时间来选举和恢复。但这恰恰证明了 **Raft 的高可用性**：即使有个别节点故障，整个系统仍然能对外提供服务，只是性能暂时下降。

通过这些增强，你不仅能测试 Rafe 协议的基本功能，还能直观地感受到它在高并发写入（**高效性**）和节点故障（**容错性**）场景下的表现。